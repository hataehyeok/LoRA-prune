
COMMAND
conda create --name lora-prune python=3.10.15


python version -> above 3.9
    Python 3.10.15 => for transformers, bitsandbytes
torch
    conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia
    stable, linux, conda, python, cuda12.4
    (but my server is CUDA version 12.5)

transformers
    pip install git+https://github.com/huggingface/transformers

datasets
    pip install datasets
    conda install -c huggingface -c conda-forge datasets

acclerate
    pip install accelerate
    conda install -c conda-forge accelerate

peft
    pip install peft

trl
    pip install trl

sklearn
    conda install scikit-learn

requests

bitsandbytes

pip install jupyter
pip install ipykernel
(from https://velog.io/@hwangbo98/vscode-vscode-ipykernel-%EC%98%A4%EB%A5%98-%EB%B0%9C%EC%83%9D%EC%8B%9C-%ED%95%B4%EA%B2%B0%EB%B2%95)




ERROR

1. bitsandbytes
    importlib.metadata.PackageNotFoundError: bitsandbytes
    pip install bitsandbytes
    https://huggingface.co/tiiuae/falcon-7b-instruct/discussions/109


2. RuntimeError: chunk expects at least a 1-dimensional tensor
    import os
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"
    https://github.com/huggingface/trl/issues/2338


3. Some parameters are on the meta device because they were offloaded to the cpu.
    - out of memory
    - https://huggingface.co/mistralai/Mixtral-8x7B-v0.1/discussions/25
    
    (1) -> reduce memory usage
    (2) -> use only merge part from importing finetuned something
    (3) -> unsloth
    (3) -> DDP


4. unsloth
    - import torch; torch.version.cuda -> 12.4
    - AttributeError: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)
    - => didn't installed well I think

5. NotADirectoryError huggingface_hub
    - conda install -c conda-forge huggingface_hub
    - https://stackoverflow.com/questions/78014793/huggingface-model-push-to-hubpeft-model-id-notadirectoryerror-errno-20-not

6. pipelines sequentially on GPU
    - You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
    - it is recommended to use 'batch processing' or provide the entire dataset directly to the pipeline
    - 

7. Evaluation module cache file doesn't exist
    - what?
    - ValueError: Evaluation module cache file doesn't exist. Please make sure that you call `add` or `add_batch` at least once before calling `compute`.

8. pip
    - ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
    - pip install --upgrade torch

9. huggingface login
    pip install huggingface_hub
    huggingface-cli login

10. TypeError: GemmaModel.forward() got an unexpected keyword argument 'num_items_in_batch'
    - transformers version problem
    - pip show transformers -> Name: transformers; Version: 4.46.3
    So, upgrade the version and use it
    - pip install --upgrade transformers
    => Name: transformers; Version: 4.47.1



- memory 더 큰 gpu에 로딩하고 -> 의미 있는 값을 뽑을 수 있으려나
- xp로 할 수 있다 -> 없다 -> 월화까지 결정하기
- 6 or 8로 일단 해보고 -> 터질 수도 있음

Experiment
1. sst2
    - base model: Accuracy on test cases: 92.12%
    - findtuned model: Accuracy on test cases: 93.69%


48GB
400

vast.ai


Ada
RTXA5000
작은거는 일단 1장 짜리로 쭉 돌려보고 큰거는 4개 구매하고 DDP로 돌리기
3090도 가성비 괜찮아서 많이 썼고 최근에는 4090 많이 쓰고있음

