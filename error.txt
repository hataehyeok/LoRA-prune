python version -> above 3.9
    Python 3.10.15 => for transformers, bitsandbytes
torch
    conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia
    stable, linux, conda, python, cuda12.4
    (but my server is CUDA version 12.5)

transformers
    pip install git+https://github.com/huggingface/transformers

datasets
    pip install datasets
    conda install -c huggingface -c conda-forge datasets

acclerate
    pip install accelerate
    conda install -c conda-forge accelerate

peft
    pip install peft

trl
    pip install trl

requests

bitsandbytes

pip install jupyter
pip install ipykernel
(from https://velog.io/@hwangbo98/vscode-vscode-ipykernel-%EC%98%A4%EB%A5%98-%EB%B0%9C%EC%83%9D%EC%8B%9C-%ED%95%B4%EA%B2%B0%EB%B2%95)



ERROR

1. bitsandbytes
    importlib.metadata.PackageNotFoundError: bitsandbytes
    pip install bitsandbytes
    https://huggingface.co/tiiuae/falcon-7b-instruct/discussions/109


2. RuntimeError: chunk expects at least a 1-dimensional tensor
    import os
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"
    https://github.com/huggingface/trl/issues/2338


3. Some parameters are on the meta device because they were offloaded to the cpu.
    - out of memory
    - https://huggingface.co/mistralai/Mixtral-8x7B-v0.1/discussions/25
    
    (1) -> reduce memory usage
    (2) -> use only merge part from importing finetuned something
    (3) -> unsloth
    (3) -> DDP


4. unsloth
    - import torch; torch.version.cuda -> 12.4
    - AttributeError: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)
    - => didn't installed well I think

5. NotADirectoryError huggingface_hub
    - conda install -c conda-forge huggingface_hub
    - https://stackoverflow.com/questions/78014793/huggingface-model-push-to-hubpeft-model-id-notadirectoryerror-errno-20-not

6. pipelines sequentially on GPU
    - You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
    - it is recommended to use 'batch processing' or provide the entire dataset directly to the pipeline
    - 



- memory 더 큰 gpu에 로딩하고 -> 의미 있는 값을 뽑을 수 있으려나
- xp로 할 수 있다 -> 없다 -> 월화까지 결정하기
- 6 or 8로 일단 해보고 -> 터질 수도 있음


최소 24는 되어야 하고 -> 크레딧 구매하고
지금 당장 결과를 뽑기 어려워보임

코드 수정
accuracy
vast.ai


1. gemma에 glue가 안먹히거나
2. 파인튜닝이 제대로 안되었거나
3. 코드가 잘못되었거나
4. 모르겠다

