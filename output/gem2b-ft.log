`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.
Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use
`config.hidden_activation` if you want to override this behaviour.
See https://github.com/huggingface/transformers/pull/29402 for more details.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]
/home/hth021002/miniconda3/envs/test/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '0.13.0'.

Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.
  warnings.warn(message, FutureWarning)
/home/hth021002/miniconda3/envs/test/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.
  warnings.warn(
max_steps is given, it will override any value given in num_train_epochs
Dataset({
    features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],
    num_rows: 22194
})
  0%|          | 0/30 [00:00<?, ?it/s]  3%|▎         | 1/30 [00:01<00:50,  1.75s/it]  7%|▋         | 2/30 [00:03<00:44,  1.59s/it] 10%|█         | 3/30 [00:04<00:41,  1.52s/it] 13%|█▎        | 4/30 [00:06<00:38,  1.50s/it] 17%|█▋        | 5/30 [00:07<00:37,  1.49s/it] 20%|██        | 6/30 [00:09<00:35,  1.48s/it] 23%|██▎       | 7/30 [00:10<00:33,  1.47s/it] 27%|██▋       | 8/30 [00:11<00:32,  1.47s/it] 30%|███       | 9/30 [00:13<00:30,  1.47s/it] 33%|███▎      | 10/30 [00:14<00:29,  1.47s/it] 37%|███▋      | 11/30 [00:16<00:27,  1.47s/it] 40%|████      | 12/30 [00:17<00:26,  1.47s/it] 43%|████▎     | 13/30 [00:19<00:24,  1.47s/it] 47%|████▋     | 14/30 [00:20<00:23,  1.47s/it] 50%|█████     | 15/30 [00:22<00:21,  1.46s/it] 53%|█████▎    | 16/30 [00:23<00:20,  1.46s/it] 57%|█████▋    | 17/30 [00:25<00:18,  1.42s/it] 60%|██████    | 18/30 [00:26<00:17,  1.43s/it] 63%|██████▎   | 19/30 [00:27<00:15,  1.44s/it] 67%|██████▋   | 20/30 [00:29<00:14,  1.45s/it] 70%|███████   | 21/30 [00:30<00:13,  1.46s/it] 73%|███████▎  | 22/30 [00:32<00:11,  1.46s/it] 77%|███████▋  | 23/30 [00:33<00:10,  1.47s/it] 80%|████████  | 24/30 [00:35<00:08,  1.47s/it] 83%|████████▎ | 25/30 [00:36<00:07,  1.47s/it] 87%|████████▋ | 26/30 [00:38<00:05,  1.48s/it] 90%|█████████ | 27/30 [00:39<00:04,  1.48s/it] 93%|█████████▎| 28/30 [00:41<00:02,  1.48s/it] 97%|█████████▋| 29/30 [00:42<00:01,  1.49s/it]100%|██████████| 30/30 [00:44<00:00,  1.51s/it]                                               100%|██████████| 30/30 [00:45<00:00,  1.51s/it]100%|██████████| 30/30 [00:45<00:00,  1.53s/it]
{'train_runtime': 45.8364, 'train_samples_per_second': 1.309, 'train_steps_per_second': 0.655, 'train_loss': 3.21671142578125, 'epoch': 0.0}
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
