`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.
Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use
`config.hidden_activation` if you want to override this behaviour.
See https://github.com/huggingface/transformers/pull/29402 for more details.

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.43s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]
/home/hth021002/miniconda3/envs/test/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '0.13.0'.

Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.
  warnings.warn(message, FutureWarning)
/home/hth021002/miniconda3/envs/test/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.
  warnings.warn(
max_steps is given, it will override any value given in num_train_epochs

  0%|          | 0/30 [00:00<?, ?it/s]
  3%|▎         | 1/30 [00:01<00:54,  1.89s/it]
  7%|▋         | 2/30 [00:03<00:49,  1.77s/it]
 10%|█         | 3/30 [00:05<00:45,  1.70s/it]
 13%|█▎        | 4/30 [00:06<00:44,  1.72s/it]
 17%|█▋        | 5/30 [00:08<00:43,  1.73s/it]
 20%|██        | 6/30 [00:10<00:38,  1.62s/it]
 23%|██▎       | 7/30 [00:11<00:38,  1.67s/it]
 27%|██▋       | 8/30 [00:13<00:35,  1.63s/it]
 30%|███       | 9/30 [00:15<00:33,  1.62s/it]
 33%|███▎      | 10/30 [00:16<00:32,  1.64s/it]
                                               

 33%|███▎      | 10/30 [00:16<00:32,  1.64s/it]
 37%|███▋      | 11/30 [00:18<00:31,  1.66s/it]
 40%|████      | 12/30 [00:19<00:28,  1.61s/it]
 43%|████▎     | 13/30 [00:21<00:27,  1.64s/it]
 47%|████▋     | 14/30 [00:23<00:27,  1.70s/it]
 50%|█████     | 15/30 [00:25<00:25,  1.72s/it]
 53%|█████▎    | 16/30 [00:27<00:26,  1.86s/it]
 57%|█████▋    | 17/30 [00:28<00:22,  1.76s/it]
 60%|██████    | 18/30 [00:30<00:20,  1.69s/it]
 63%|██████▎   | 19/30 [00:32<00:18,  1.70s/it]
 67%|██████▋   | 20/30 [00:33<00:17,  1.71s/it]
                                               

 67%|██████▋   | 20/30 [00:33<00:17,  1.71s/it]
 70%|███████   | 21/30 [00:35<00:15,  1.73s/it]
 73%|███████▎  | 22/30 [00:37<00:13,  1.69s/it]
 77%|███████▋  | 23/30 [00:39<00:12,  1.85s/it]
 80%|████████  | 24/30 [00:41<00:10,  1.79s/it]
 83%|████████▎ | 25/30 [00:42<00:08,  1.75s/it]
 87%|████████▋ | 26/30 [00:44<00:06,  1.68s/it]
 90%|█████████ | 27/30 [00:46<00:05,  1.82s/it]
 93%|█████████▎| 28/30 [00:48<00:03,  1.78s/it]
 97%|█████████▋| 29/30 [00:50<00:01,  1.81s/it]
100%|██████████| 30/30 [00:51<00:00,  1.76s/it]
                                               

100%|██████████| 30/30 [00:51<00:00,  1.76s/it]
                                               

100%|██████████| 30/30 [00:53<00:00,  1.76s/it]
100%|██████████| 30/30 [00:53<00:00,  1.77s/it]
{'loss': 12.9381, 'grad_norm': 9.301559448242188, 'learning_rate': 2e-05, 'epoch': 0.0}
{'loss': 11.8092, 'grad_norm': 15.86178207397461, 'learning_rate': 3.6e-05, 'epoch': 0.0}
{'loss': 9.4994, 'grad_norm': 30.58384895324707, 'learning_rate': 5.4000000000000005e-05, 'epoch': 0.01}
{'train_runtime': 53.0508, 'train_samples_per_second': 9.048, 'train_steps_per_second': 0.565, 'train_loss': 11.415544128417968, 'epoch': 0.01}

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  1.33it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.55it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.24it/s]
